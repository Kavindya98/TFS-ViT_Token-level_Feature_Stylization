Not launched: ./Results/PACS/RandConv_CNN/ResNet_18_2/t013_s0 ('PACS', 'RandConv_CNN', [0, 1, 3], 0)
Not launched: ./Results/PACS/RandConv_CNN/ResNet_18_2/t013_s1 ('PACS', 'RandConv_CNN', [0, 1, 3], 0)
2 jobs: 0 done, 0 incomplete, 2 not launched.
python -m domainbed.scripts.train --algorithm RandConv_CNN --data_dir /media/SSD2/Dataset --dataset PACS --holdout_fraction 0.2 --hparams '{"batch_size":32,"lr":0.0001,"resnet_dropout":0.0,"weight_decay":0.0,"resnet18":true,"fixed_featurizer":false,"empty_fc":true}' --hparams_seed 0 --output_dir ./Results/PACS/RandConv_CNN/ResNet_18_2/t013_s0 --seed 1239948206 --task domain_generalization --test_envs 0 1 3 --trial_seed 0

python -m domainbed.scripts.train --algorithm RandConv_CNN --data_dir /media/SSD2/Dataset --dataset PACS --holdout_fraction 0.2 --hparams '{"batch_size":32,"lr":0.0001,"resnet_dropout":0.0,"weight_decay":0.0,"resnet18":true,"fixed_featurizer":false,"empty_fc":true}' --hparams_seed 0 --output_dir ./Results/PACS/RandConv_CNN/ResNet_18_2/t013_s1 --seed 73519977 --task domain_generalization --test_envs 0 1 3 --trial_seed 1
About to delete 0 jobs.
Good to go
Deleting...
Deleted 0 jobs!
  0%|          | 0/2 [00:00<?, ?it/s]                                     Environment:
	Python: 3.8.8
	PyTorch: 2.0.1+cu117
	Torchvision: 0.15.2+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.20.1
	PIL: 8.2.0
Args:
	algorithm: RandConv_CNN
	checkpoint_freq: None
	data_dir: /media/SSD2/Dataset
	dataset: PACS
	holdout_fraction: 0.2
	hparams: {"batch_size":32,"lr":0.0001,"resnet_dropout":0.0,"weight_decay":0.0,"resnet18":true,"fixed_featurizer":false,"empty_fc":true}
	hparams_seed: 0
	output_dir: ./Results/PACS/RandConv_CNN/ResNet_18_2/t013_s0
	save_best_model: True
	save_model_every_checkpoint: False
	seed: 1239948206
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [0, 1, 3]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	backbone: DeitSmall
	batch_size: 32
	class_balanced: False
	consistency_loss_w: 10.0
	custom_train: 0
	custom_train_val: False
	custom_val: 0
	data_augmentation: False
	digits: True
	empty_fc: True
	empty_head: False
	eval: False
	fixed_featurizer: False
	identity_prob: 0.0
	invariant_loss: True
	lr: 0.0001
	mixing: True
	nonlinear_classifier: False
	randomize_kernel: True
	resnet18: True
	resnet_dropout: 0.0
	test_env: [0, 1, 3]
	weight_decay: 0.0
	weight_decay_d: 0.0
device: cuda
Current cuda device  0
env  A  in  1639  out  409
env  C  in  1876  out  468
env  P  in  1336  out  334
env  S  in  3144  out  785
/home/kavindya/anaconda3/envs/ViT_DGbed_2/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/kavindya/anaconda3/envs/ViT_DGbed_2/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Environment:
	Python: 3.8.8
	PyTorch: 2.0.1+cu117
	Torchvision: 0.15.2+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.20.1
	PIL: 8.2.0
Args:
	algorithm: RandConv_CNN
	checkpoint_freq: None
	data_dir: /media/SSD2/Dataset
	dataset: PACS
	holdout_fraction: 0.2
	hparams: {"batch_size":32,"lr":0.0001,"resnet_dropout":0.0,"weight_decay":0.0,"resnet18":true,"fixed_featurizer":false,"empty_fc":true}
	hparams_seed: 0
	output_dir: ./Results/PACS/RandConv_CNN/ResNet_18_2/t013_s1
	save_best_model: True
	save_model_every_checkpoint: False
	seed: 73519977
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [0, 1, 3]
	trial_seed: 1
	uda_holdout_fraction: 0
HParams:
	backbone: DeitSmall
	batch_size: 32
	class_balanced: False
	consistency_loss_w: 10.0
	custom_train: 0
	custom_train_val: False
	custom_val: 0
	data_augmentation: False
	digits: True
	empty_fc: True
	empty_head: False
	eval: False
	fixed_featurizer: False
	identity_prob: 0.0
	invariant_loss: True
	lr: 0.0001
	mixing: True
	nonlinear_classifier: False
	randomize_kernel: True
	resnet18: True
	resnet_dropout: 0.0
	test_env: [0, 1, 3]
	weight_decay: 0.0
	weight_decay_d: 0.0
device: cuda
Current cuda device  0
env  A  in  1639  out  409
env  C  in  1876  out  468
env  P  in  1336  out  334
env  S  in  3144  out  785
Downloading: "https://download.pytorch.org/models/resnet18-f37072fd.pth" to /home/kavindya/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth
  0%|          | 0.00/44.7M [00:00<?, ?B/s] 19%|#9        | 8.52M/44.7M [00:00<00:00, 84.4MB/s] 46%|####6     | 20.8M/44.7M [00:00<00:00, 110MB/s]  70%|#######   | 31.3M/44.7M [00:00<00:00, 109MB/s] 97%|#########6| 43.2M/44.7M [00:00<00:00, 110MB/s]100%|##########| 44.7M/44.7M [00:00<00:00, 110MB/s]
moving to the classifier
full_model_tuning_only
/home/kavindya/anaconda3/envs/ViT_DGbed_2/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/kavindya/anaconda3/envs/ViT_DGbed_2/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
+ checkpoint_freq: 300
moving to the classifier
full_model_tuning_only
+ checkpoint_freq: 300
Best model upto now
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  epoch         loss          mem_gb        step          step_time    
0.3136058572  0.3056234719  0.2068230277  0.1858974359  0.4880239521  0.4610778443  0.1370865140  0.1694267516  0.0000000000  1.8330690861  2.1003932953  0             1.7701544762 
Best model upto now
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  epoch         loss          mem_gb        step          step_time    
0.2263575351  0.1907090465  0.2100213220  0.2008547009  0.3884730539  0.3862275449  0.1676208651  0.1592356688  0.0000000000  2.5251200199  2.1332921982  0             1.3584887981 
Best model upto now
0.5527760830  0.5550122249  0.2867803838  0.2606837607  0.9962574850  0.9461077844  0.3466921120  0.4000000000  7.1856287425  0.2401416077  2.2095742226  300           0.0803966904 
Best model upto now
0.6253813301  0.6088019560  0.2771855011  0.2542735043  0.9932634731  0.9760479042  0.2608142494  0.2598726115  7.1856287425  0.2721557616  2.2435102463  300           0.1313381457 
0.6052471019  0.6332518337  0.2803837953  0.2649572650  0.9970059880  0.9341317365  0.2837150127  0.3133757962  14.371257485  0.1157979206  2.2095742226  600           0.0805771653 
Best model upto now
0.6241610738  0.6381418093  0.3214285714  0.3012820513  0.9992514970  0.9491017964  0.4083969466  0.4292993631  21.556886227  0.0474394019  2.2095742226  900           0.0808316080 
0.5857230018  0.5672371638  0.3608742004  0.3397435897  0.9970059880  0.9730538922  0.4704198473  0.4484076433  14.371257485  0.0893987408  2.2435102463  600           0.1313276259 
0.5210494204  0.5305623472  0.3619402985  0.3354700855  0.9917664671  0.9101796407  0.5302162850  0.5503184713  28.742514970  0.0503343889  2.2095742226  1200          0.0808674622 
0.5424039048  0.5427872861  0.4371002132  0.4380341880  0.9992514970  0.9520958084  0.5731552163  0.5859872611  21.556886227  0.0565884079  2.2435102463  900           0.1312143858 
Best model upto now
0.6143990238  0.6356968215  0.3555437100  0.3333333333  1.0000000000  0.9550898204  0.5438931298  0.5554140127  35.928143712  0.0580363136  2.2095742226  1500          0.0812313310 
0.5948749237  0.6283618582  0.2809168443  0.2628205128  0.9992514970  0.9311377246  0.3791348601  0.4025477707  43.113772455  0.0559597779  2.2104253769  1800          0.0807020990 
0.6272117145  0.6210268949  0.3320895522  0.3076923077  1.0000000000  0.9700598802  0.4274809160  0.4318471338  28.742514970  0.0608894746  2.2435102463  1200          0.1318708475 
0.5405735204  0.5354523227  0.3304904051  0.2863247863  1.0000000000  0.9251497006  0.4611959288  0.4815286624  50.299401197  0.0059764220  2.2104253769  2100          0.0810209982 
Best model upto now
0.5704697987  0.5501222494  0.4163113006  0.4038461538  0.9992514970  0.9790419162  0.6081424936  0.6076433121  35.928143712  0.0384172287  2.2435102463  1500          0.1316698607 
0.5546064674  0.5599022005  0.2926439232  0.2777777778  0.9992514970  0.9071856287  0.4182569975  0.4369426752  57.485029940  0.0340780763  2.2104253769  2400          0.0808091998 
0.5930445394  0.5916870416  0.4296375267  0.3846153846  1.0000000000  0.9401197605  0.5461195929  0.5732484076  64.670658682  0.0177150276  2.2104253769  2700          0.0808204730 
0.1873093350  0.1760391198  0.1684434968  0.1559829060  0.1122754491  0.1167664671  0.1984732824  0.1885350318  43.113772455  nan           2.2437524796  1800          0.1291157556 
0.1873093350  0.1760391198  0.1700426439  0.1495726496  0.1115269461  0.1197604790  0.1965648855  0.1961783439  71.856287425  nan           2.2104253769  3000          0.0813559683 
0.1873093350  0.1760391198  0.1684434968  0.1559829060  0.1122754491  0.1167664671  0.1984732824  0.1885350318  50.299401197  nan           2.2437524796  2100          0.1282984360 
0.1873093350  0.1760391198  0.1700426439  0.1495726496  0.1115269461  0.1197604790  0.1965648855  0.1961783439  79.041916167  nan           2.2104253769  3300          0.0801728376 
0.1873093350  0.1760391198  0.1700426439  0.1495726496  0.1115269461  0.1197604790  0.1965648855  0.1961783439  86.227544910  nan           2.2104253769  3600          0.0796850681 
0.1873093350  0.1760391198  0.1684434968  0.1559829060  0.1122754491  0.1167664671  0.1984732824  0.1885350318  57.485029940  nan           2.2437524796  2400          0.1284283598 
0.1873093350  0.1760391198  0.1700426439  0.1495726496  0.1115269461  0.1197604790  0.1965648855  0.1961783439  93.413173652  nan           2.2104253769  3900          0.0800806475 
0.1873093350  0.1760391198  0.1684434968  0.1559829060  0.1122754491  0.1167664671  0.1984732824  0.1885350318  64.670658682  nan           2.2437524796  2700          0.1284923283 
0.1873093350  0.1760391198  0.1700426439  0.1495726496  0.1115269461  0.1197604790  0.1965648855  0.1961783439  100.59880239  nan           2.2104253769  4200          0.0803506589 
0.1873093350  0.1760391198  0.1700426439  0.1495726496  0.1115269461  0.1197604790  0.1965648855  0.1961783439  107.78443113  nan           2.2104253769  4500          0.0797695669 
0.1873093350  0.1760391198  0.1684434968  0.1559829060  0.1122754491  0.1167664671  0.1984732824  0.1885350318  71.856287425  nan           2.2437524796  3000          0.1284896596 
0.1873093350  0.1760391198  0.1700426439  0.1495726496  0.1115269461  0.1197604790  0.1965648855  0.1961783439  114.97005988  nan           2.2104253769  4800          0.0804456250 
0.1873093350  0.1760391198  0.1700426439  0.1495726496  0.1115269461  0.1197604790  0.1965648855  0.1961783439  119.76047904  nan           2.2104253769  5000          0.0799349582 
0.1873093350  0.1760391198  0.1684434968  0.1559829060  0.1122754491  0.1167664671  0.1984732824  0.1885350318  79.041916167  nan           2.2437524796  3300          0.1292602897 
0.1873093350  0.1760391198  0.1684434968  0.1559829060  0.1122754491  0.1167664671  0.1984732824  0.1885350318  86.227544910  nan           2.2437524796  3600          0.1288405403 
0.1873093350  0.1760391198  0.1684434968  0.1559829060  0.1122754491  0.1167664671  0.1984732824  0.1885350318  93.413173652  nan           2.2437524796  3900          0.1287393530 
0.1873093350  0.1760391198  0.1684434968  0.1559829060  0.1122754491  0.1167664671  0.1984732824  0.1885350318  100.59880239  nan           2.2437524796  4200          0.1287445919 
0.1873093350  0.1760391198  0.1684434968  0.1559829060  0.1122754491  0.1167664671  0.1984732824  0.1885350318  107.78443113  nan           2.2437524796  4500          0.1290865493 
0.1873093350  0.1760391198  0.1684434968  0.1559829060  0.1122754491  0.1167664671  0.1984732824  0.1885350318  114.97005988  nan           2.2437524796  4800          0.1291489029 
0.1873093350  0.1760391198  0.1684434968  0.1559829060  0.1122754491  0.1167664671  0.1984732824  0.1885350318  119.76047904  nan           2.2437524796  5000          0.1293233883 
Not launched: ./Results/PACS/RandConv_CNN/ResNet_18_2/t013_s0 ('PACS', 'RandConv_CNN', [0, 1, 3], 0)
Not launched: ./Results/PACS/RandConv_CNN/ResNet_18_2/t013_s1 ('PACS', 'RandConv_CNN', [0, 1, 3], 0)
2 jobs: 0 done, 0 incomplete, 2 not launched.
python -m domainbed.scripts.train --algorithm RandConv_CNN --data_dir /media/SSD2/Dataset --dataset PACS --holdout_fraction 0.2 --hparams '{"batch_size":32,"lr":0.0001,"resnet_dropout":0.0,"weight_decay":0.0,"resnet18":true,"fixed_featurizer":false,"empty_fc":true}' --hparams_seed 0 --output_dir ./Results/PACS/RandConv_CNN/ResNet_18_2/t013_s0 --seed 1239948206 --task domain_generalization --test_envs 0 1 3 --trial_seed 0

python -m domainbed.scripts.train --algorithm RandConv_CNN --data_dir /media/SSD2/Dataset --dataset PACS --holdout_fraction 0.2 --hparams '{"batch_size":32,"lr":0.0001,"resnet_dropout":0.0,"weight_decay":0.0,"resnet18":true,"fixed_featurizer":false,"empty_fc":true}' --hparams_seed 0 --output_dir ./Results/PACS/RandConv_CNN/ResNet_18_2/t013_s1 --seed 73519977 --task domain_generalization --test_envs 0 1 3 --trial_seed 1
About to launch 2 jobs.
Good to go
Launching...
Making job directories:
WARNING: using experimental multi_gpu_launcher.
Launched 2 jobs!
device: cuda:3
Current cuda device  0
ViTBase Network
full_model_tuning_only
Classes ++++ ['00_dog_', '01_bird_', '02_wheeled vehicle_', '03_reptile_', '04_carnivore_', '05_insect_', '06_musical instrument_', '07_primate_', '08_fish_']
Loading dataset
0it [00:00, ?it/s]1it [00:00,  4.11it/s]2it [00:00,  3.97it/s]3it [00:00,  3.51it/s]4it [00:01,  2.87it/s]5it [00:01,  2.68it/s]5it [00:01,  2.96it/s]
env_mixed_next_acc 0.0006453434437139515
env_mixed_rand_acc 0.0006453434437139515
env_mixed_same_acc 0.0007058443915621345
env_no_fg_acc 0.0005445085306336466
env_only_fg_acc 0.0006453434437139515
device: cuda:3
Current cuda device  0
ViTBase Network
full_model_tuning_only
Classes ++++ ['00_dog_', '01_bird_', '02_wheeled vehicle_', '03_reptile_', '04_carnivore_', '05_insect_', '06_musical instrument_', '07_primate_', '08_fish_']
Loading dataset
0it [00:00, ?it/s]1it [00:00,  3.94it/s]2it [00:00,  4.00it/s]3it [00:00,  3.53it/s]4it [00:01,  3.39it/s]5it [00:01,  3.14it/s]5it [00:01,  3.34it/s]
env_mixed_next_acc 0.6446577663050055
env_mixed_rand_acc 0.6753519138466503
env_mixed_same_acc 0.7829831000685678
env_no_fg_acc 0.4750332755213165
env_only_fg_acc 0.6145887952244585
device: cuda:3
Current cuda device  0
Using cache found in /home/kavindya/.cache/torch/hub/facebookresearch_deit_main
DeiTBase Network
full_model_tuning_only
Classes ++++ ['00_dog_', '01_bird_', '02_wheeled vehicle_', '03_reptile_', '04_carnivore_', '05_insect_', '06_musical instrument_', '07_primate_', '08_fish_']
Loading dataset
0it [00:00, ?it/s]1it [00:00,  3.45it/s]2it [00:00,  3.47it/s]3it [00:00,  3.41it/s]4it [00:01,  3.15it/s]5it [00:01,  3.06it/s]5it [00:01,  3.17it/s]
env_mixed_next_acc 0.7507965958133344
env_mixed_rand_acc 0.7738676239261082
env_mixed_same_acc 0.8690154479086839
env_no_fg_acc 0.6737788892025975
env_only_fg_acc 0.8432218771427419
device: cuda:3
Current cuda device  0
taken the whole pretrained network
/home/kavindya/anaconda3/envs/ViT_DGbed_2/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/kavindya/anaconda3/envs/ViT_DGbed_2/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Downloading: "https://download.pytorch.org/models/resnet50-0676ba61.pth" to /home/kavindya/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth
  0%|          | 0.00/97.8M [00:00<?, ?B/s]  6%|▌         | 5.88M/97.8M [00:00<00:01, 61.5MB/s] 16%|█▋        | 16.0M/97.8M [00:00<00:00, 85.8MB/s] 28%|██▊       | 27.2M/97.8M [00:00<00:00, 99.8MB/s] 39%|███▉      | 38.1M/97.8M [00:00<00:00, 105MB/s]  50%|█████     | 49.0M/97.8M [00:00<00:00, 108MB/s] 61%|██████▏   | 60.0M/97.8M [00:00<00:00, 111MB/s] 73%|███████▎  | 71.0M/97.8M [00:00<00:00, 112MB/s] 84%|████████▍ | 82.0M/97.8M [00:00<00:00, 113MB/s] 95%|█████████▌| 93.1M/97.8M [00:00<00:00, 114MB/s]100%|██████████| 97.8M/97.8M [00:00<00:00, 108MB/s]
full_model_tuning_only
Classes ++++ ['00_dog_', '01_bird_', '02_wheeled vehicle_', '03_reptile_', '04_carnivore_', '05_insect_', '06_musical instrument_', '07_primate_', '08_fish_']
Loading dataset
0it [00:00, ?it/s]1it [00:00,  5.38it/s]2it [00:00,  4.12it/s]3it [00:00,  3.32it/s]4it [00:01,  3.35it/s]5it [00:01,  3.03it/s]5it [00:01,  3.29it/s]
env_mixed_next_acc 0.6844875569717259
env_mixed_rand_acc 0.7139111846085588
env_mixed_same_acc 0.8159561166458275
env_no_fg_acc 0.5159924172145364
env_only_fg_acc 0.7552736659541
device: cuda:3
Current cuda device  0
taken the whole pretrained network
/home/kavindya/anaconda3/envs/ViT_DGbed_2/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/kavindya/anaconda3/envs/ViT_DGbed_2/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
full_model_tuning_only
Classes ++++ ['00_dog_', '01_bird_', '02_wheeled vehicle_', '03_reptile_', '04_carnivore_', '05_insect_', '06_musical instrument_', '07_primate_', '08_fish_']
Loading dataset
0it [00:00, ?it/s]1it [00:00,  5.87it/s]2it [00:00,  4.06it/s]3it [00:00,  3.94it/s]4it [00:01,  3.27it/s]5it [00:01,  3.24it/s]5it [00:01,  3.49it/s]
env_mixed_next_acc 0.5940588069213084
env_mixed_rand_acc 0.6344532731012786
env_mixed_same_acc 0.7618481022869358
env_no_fg_acc 0.4414350824829589
env_only_fg_acc 0.664663413060138
