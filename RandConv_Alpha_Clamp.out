nohup: ignoring input
/media/SSD2/kavindya/Model/TFS-ViT_Token-level_Feature_Stylization/domainbed/visiontransformer.py:962: UserWarning: Overwriting vit_small_patch16_224 in registry with domainbed.visiontransformer.vit_small_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def vit_small_patch16_224(pretrained=False, **kwargs):
/media/SSD2/kavindya/Model/TFS-ViT_Token-level_Feature_Stylization/domainbed/visiontransformer.py:975: UserWarning: Overwriting vit_base_patch16_224 in registry with domainbed.visiontransformer.vit_base_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def vit_base_patch16_224(pretrained=False, **kwargs):
/media/SSD2/kavindya/Model/TFS-ViT_Token-level_Feature_Stylization/domainbed/visiontransformer.py:987: UserWarning: Overwriting vit_base_patch16_384 in registry with domainbed.visiontransformer.vit_base_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def vit_base_patch16_384(pretrained=False, **kwargs):
/media/SSD2/kavindya/Model/TFS-ViT_Token-level_Feature_Stylization/domainbed/visiontransformer.py:998: UserWarning: Overwriting vit_base_patch32_384 in registry with domainbed.visiontransformer.vit_base_patch32_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def vit_base_patch32_384(pretrained=False, **kwargs):
/media/SSD2/kavindya/Model/TFS-ViT_Token-level_Feature_Stylization/domainbed/visiontransformer.py:1009: UserWarning: Overwriting vit_large_patch16_224 in registry with domainbed.visiontransformer.vit_large_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def vit_large_patch16_224(pretrained=False, **kwargs):
/media/SSD2/kavindya/Model/TFS-ViT_Token-level_Feature_Stylization/domainbed/visiontransformer.py:1020: UserWarning: Overwriting vit_large_patch16_384 in registry with domainbed.visiontransformer.vit_large_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def vit_large_patch16_384(pretrained=False, **kwargs):
/media/SSD2/kavindya/Model/TFS-ViT_Token-level_Feature_Stylization/domainbed/visiontransformer.py:1031: UserWarning: Overwriting vit_large_patch32_384 in registry with domainbed.visiontransformer.vit_large_patch32_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def vit_large_patch32_384(pretrained=False, **kwargs):
/media/SSD2/kavindya/Model/TFS-ViT_Token-level_Feature_Stylization/domainbed/visiontransformer.py:1057: UserWarning: Overwriting vit_small_resnet26d_224 in registry with domainbed.visiontransformer.vit_small_resnet26d_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def vit_small_resnet26d_224(pretrained=False, **kwargs):
/media/SSD2/kavindya/Model/TFS-ViT_Token-level_Feature_Stylization/domainbed/visiontransformer.py:1077: UserWarning: Overwriting vit_base_resnet26d_224 in registry with domainbed.visiontransformer.vit_base_resnet26d_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def vit_base_resnet26d_224(pretrained=False, **kwargs):
/media/SSD2/kavindya/Model/TFS-ViT_Token-level_Feature_Stylization/domainbed/visiontransformer.py:1087: UserWarning: Overwriting vit_base_resnet50d_224 in registry with domainbed.visiontransformer.vit_base_resnet50d_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def vit_base_resnet50d_224(pretrained=False, **kwargs):
Not launched: ./Results/ImageNet/Fullset/Small_Epoch_Clipped_Alpha/RandConv/t1_s2 ('ImageNet', 'RandConv_CNN', [1], 0)
1 jobs: 0 done, 0 incomplete, 1 not launched.
python -m domainbed.scripts.train --algorithm RandConv_CNN --data_dir /media/SSD2/Dataset --dataset ImageNet --holdout_fraction 0.2 --hparams '{"batch_size":64,"lr":0.0001,"resnet_dropout":0.0,"alpha_min":0.5,"alpha_max":1.0,"weight_decay":0.0,"custom_train_val":true,"custom_train":0,"custom_val":1,"resnet18":false,"fixed_featurizer":false}' --hparams_seed 0 --output_dir ./Results/ImageNet/Fullset/Small_Epoch_Clipped_Alpha/RandConv/t1_s2 --seed 1637210862 --task domain_generalization --test_envs 1 --trial_seed 2
About to delete 0 jobs.
Good to go
Deleting...
Deleted 0 jobs!
/media/SSD2/kavindya/Model/TFS-ViT_Token-level_Feature_Stylization/domainbed/visiontransformer.py:962: UserWarning: Overwriting vit_small_patch16_224 in registry with domainbed.visiontransformer.vit_small_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def vit_small_patch16_224(pretrained=False, **kwargs):
/media/SSD2/kavindya/Model/TFS-ViT_Token-level_Feature_Stylization/domainbed/visiontransformer.py:975: UserWarning: Overwriting vit_base_patch16_224 in registry with domainbed.visiontransformer.vit_base_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def vit_base_patch16_224(pretrained=False, **kwargs):
/media/SSD2/kavindya/Model/TFS-ViT_Token-level_Feature_Stylization/domainbed/visiontransformer.py:987: UserWarning: Overwriting vit_base_patch16_384 in registry with domainbed.visiontransformer.vit_base_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def vit_base_patch16_384(pretrained=False, **kwargs):
/media/SSD2/kavindya/Model/TFS-ViT_Token-level_Feature_Stylization/domainbed/visiontransformer.py:998: UserWarning: Overwriting vit_base_patch32_384 in registry with domainbed.visiontransformer.vit_base_patch32_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def vit_base_patch32_384(pretrained=False, **kwargs):
/media/SSD2/kavindya/Model/TFS-ViT_Token-level_Feature_Stylization/domainbed/visiontransformer.py:1009: UserWarning: Overwriting vit_large_patch16_224 in registry with domainbed.visiontransformer.vit_large_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def vit_large_patch16_224(pretrained=False, **kwargs):
/media/SSD2/kavindya/Model/TFS-ViT_Token-level_Feature_Stylization/domainbed/visiontransformer.py:1020: UserWarning: Overwriting vit_large_patch16_384 in registry with domainbed.visiontransformer.vit_large_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def vit_large_patch16_384(pretrained=False, **kwargs):
/media/SSD2/kavindya/Model/TFS-ViT_Token-level_Feature_Stylization/domainbed/visiontransformer.py:1031: UserWarning: Overwriting vit_large_patch32_384 in registry with domainbed.visiontransformer.vit_large_patch32_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def vit_large_patch32_384(pretrained=False, **kwargs):
/media/SSD2/kavindya/Model/TFS-ViT_Token-level_Feature_Stylization/domainbed/visiontransformer.py:1057: UserWarning: Overwriting vit_small_resnet26d_224 in registry with domainbed.visiontransformer.vit_small_resnet26d_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def vit_small_resnet26d_224(pretrained=False, **kwargs):
/media/SSD2/kavindya/Model/TFS-ViT_Token-level_Feature_Stylization/domainbed/visiontransformer.py:1077: UserWarning: Overwriting vit_base_resnet26d_224 in registry with domainbed.visiontransformer.vit_base_resnet26d_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def vit_base_resnet26d_224(pretrained=False, **kwargs):
/media/SSD2/kavindya/Model/TFS-ViT_Token-level_Feature_Stylization/domainbed/visiontransformer.py:1087: UserWarning: Overwriting vit_base_resnet50d_224 in registry with domainbed.visiontransformer.vit_base_resnet50d_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.
  def vit_base_resnet50d_224(pretrained=False, **kwargs):
Not launched: ./Results/ImageNet/Fullset/Small_Epoch_Clipped_Alpha/RandConv/t1_s2 ('ImageNet', 'RandConv_CNN', [1], 0)
1 jobs: 0 done, 0 incomplete, 1 not launched.
python -m domainbed.scripts.train --algorithm RandConv_CNN --data_dir /media/SSD2/Dataset --dataset ImageNet --holdout_fraction 0.2 --hparams '{"batch_size":64,"lr":0.0001,"resnet_dropout":0.0,"alpha_min":0.5,"alpha_max":1.0,"weight_decay":0.0,"custom_train_val":true,"custom_train":0,"custom_val":1,"resnet18":false,"fixed_featurizer":false}' --hparams_seed 0 --output_dir ./Results/ImageNet/Fullset/Small_Epoch_Clipped_Alpha/RandConv/t1_s2 --seed 1637210862 --task domain_generalization --test_envs 1 --trial_seed 2
About to launch 1 jobs.
Good to go
Launching...
Making job directories:
  0%|          | 0/1 [00:00<?, ?it/s]                                     WARNING: using experimental multi_gpu_launcher.
CUDA_VISIBLE_DEVICES:  0
Environment:
	Python: 3.8.8
	PyTorch: 2.0.1+cu117
	Torchvision: 0.15.2+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.20.1
	PIL: 8.2.0
Args:
	algorithm: RandConv_CNN
	checkpoint_freq: None
	data_dir: /media/SSD2/Dataset
	dataset: ImageNet
	holdout_fraction: 0.2
	hparams: {"batch_size":64,"lr":0.0001,"resnet_dropout":0.0,"alpha_min":0.5,"alpha_max":1.0,"weight_decay":0.0,"custom_train_val":true,"custom_train":0,"custom_val":1,"resnet18":false,"fixed_featurizer":false}
	hparams_seed: 0
	output_dir: ./Results/ImageNet/Fullset/Small_Epoch_Clipped_Alpha/RandConv/t1_s2
	save_best_model: True
	save_model_every_checkpoint: False
	seed: 1637210862
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [1]
	trial_seed: 2
	uda_holdout_fraction: 0
HParams:
	alpha_max: 1.0
	alpha_min: 0.5
	backbone: DeitSmall
	batch_size: 64
	class_balanced: False
	consistency_loss_w: 10.0
	custom_train: 0
	custom_train_val: True
	custom_val: 1
	data_augmentation: False
	digits: True
	empty_fc: False
	empty_head: False
	eval: False
	fixed_featurizer: False
	identity_prob: 0.0
	invariant_loss: True
	lr: 0.0001
	mixing: True
	nonlinear_classifier: False
	randomize_kernel: True
	resnet18: False
	resnet_dropout: 0.0
	test_env: [1]
	weight_decay: 0.0
	weight_decay_d: 0.0
device: cuda
Current cuda device  0
[INFO] NOT Doing Data Augmentation
[INFO] NOT Doing Data Augmentation
50000  length of val  1281167  length of train
env  0  :  train  in  1281167
env  1  :  valid  out  50000
taken the whole pretrained network
/home/kavindya/anaconda3/envs/ViT_DGbed_2/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/kavindya/anaconda3/envs/ViT_DGbed_2/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
full_model_tuning_only
+ checkpoint_freq: 1000
Best model upto now
env1_out_acc  env1_out_los  epoch         loss          mem_gb        step          step_time     train_acc    
0.2216000000  4.4302082318  0.0000000000  8.8044147491  15.974832534  0             2.0138571262  0.2968750000 
Best model upto now
0.4072200000  2.7476485617  0.0499544556  3.4895043743  16.175758838  1000          0.7362307243  0.4076875000 
Best model upto now
0.4386400000  2.5653705935  0.0999089112  3.0291780274  16.175758838  2000          0.7355936205  0.4707500000 
Best model upto now
0.4639400000  2.4363131837  0.1498633668  2.8682980738  16.177283287  3000          0.7340115075  0.4905000000 
0.4487800000  2.5191712803  0.1998178223  2.7811231258  16.177283287  4000          0.7333929598  0.5046250000 
Best model upto now
0.4843000000  2.3539456379  0.2497722779  2.7189480535  16.177283287  5000          0.7334344120  0.5151718750 
