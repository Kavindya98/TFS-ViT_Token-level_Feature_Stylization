Incomplete: ./Results/DIGITS/RandConv/t1234_s0 ('DIGITS', 'RandConv', [1, 2, 3, 4], 0)
1 jobs: 0 done, 1 incomplete, 0 not launched.
python -m domainbed.scripts.train --algorithm RandConv --data_dir /home/kavindya/data/Models/DATA --dataset DIGITS --holdout_fraction 0.2 --hparams '{"batch_size":32,"lr":5e-05,"resnet_dropout":0.0,"weight_decay":0.0}' --hparams_seed 0 --output_dir ./Results/DIGITS/RandConv/t1234_s0 --seed 1270687741 --task domain_generalization --test_envs 1 2 3 4 --trial_seed 0
About to delete 1 jobs.
Good to go
Deleting...
Deleted 1 jobs!

  0%|          | 0/1 [00:00<?, ?it/s]
                                     Environment:
	Python: 3.8.8
	PyTorch: 1.8.0
	Torchvision: 0.9.0
	CUDA: 10.2
	CUDNN: 7605
	NumPy: 1.20.1
	PIL: 8.2.0
Args:
	algorithm: RandConv
	checkpoint_freq: None
	data_dir: /home/kavindya/data/Models/DATA
	dataset: DIGITS
	holdout_fraction: 0.2
	hparams: {"batch_size":32,"lr":5e-05,"resnet_dropout":0.0,"weight_decay":0.0}
	hparams_seed: 0
	output_dir: ./Results/DIGITS/RandConv/t1234_s0
	save_best_model: True
	save_model_every_checkpoint: False
	seed: 1270687741
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [1, 2, 3, 4]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	backbone: DeitSmall
	batch_size: 32
	class_balanced: False
	consistency_loss_w: 10.0
	data_augmentation: True
	digits: True
	identity_prob: 0.0
	invariant_loss: True
	lr: 5e-05
	mixing: True
	nonlinear_classifier: False
	randomize_kernel: True
	resnet18: False
	resnet_dropout: 0.0
	test_env: [1, 2, 3, 4]
	weight_decay: 0.0
device: cuda
/home/kavindya/data/Models/DATA/digits/MNISTM/processed/mnist_m_test.pt
Using downloaded and verified file: /home/kavindya/data/Models/DATA/digits/train_32x32.mat
/home/kavindya/data/Models/DATA/digits/SYN/processed/synth_test.pt
moving to the classifier
Parameter containing:
tensor([[ 0.0025, -0.0246, -0.0113,  ...,  0.0051,  0.0109, -0.0274],
        [-0.0153, -0.0174,  0.0239,  ...,  0.0201, -0.0240,  0.0197],
        [-0.0280,  0.0164,  0.0122,  ...,  0.0265, -0.0165, -0.0284],
        ...,
        [ 0.0274,  0.0064, -0.0309,  ...,  0.0176,  0.0281, -0.0019],
        [ 0.0267, -0.0048,  0.0099,  ..., -0.0001,  0.0273,  0.0133],
        [ 0.0264, -0.0044, -0.0092,  ..., -0.0252,  0.0151, -0.0167]],
       requires_grad=True)
Parameter containing:
tensor([-1.3876e-02,  2.9681e-02,  4.9077e-05, -2.4892e-02, -2.1179e-02,
         1.8713e-02, -3.0336e-02,  1.7954e-03,  2.6922e-02,  1.6087e-02],
       requires_grad=True)
+ checkpoint_freq: 250
Best model upto now
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  env4_in_acc   env4_out_acc  epoch         loss          mem_gb        step          step_time    
0.1131428571  0.1106428571  0.1040000000  0.1185000000  0.1029246152  0.1039519487  0.0529265255  0.0598503741  0.0881852676  0.0921465969  0.0000000000  2.3015723228  0.0929193497  0             0.0641081333 
Best model upto now
0.8992857143  0.8981428571  0.5442500000  0.5490000000  0.2147391052  0.2064022934  0.6407222914  0.6533665835  0.3150595316  0.3183246073  4.9813200498  1.8403305552  0.1390748024  250           0.0259974155 
Best model upto now
0.9206785714  0.9202857143  0.6602500000  0.6545000000  0.2727365799  0.2716538120  0.7297633873  0.7107231920  0.4219547298  0.4303664921  9.9626400996  1.1436279489  0.1394424438  500           0.0248845682 
Best model upto now
0.9368750000  0.9351428571  0.7316250000  0.7135000000  0.2971880012  0.2910381544  0.7515566625  0.7755610973  0.4370011775  0.4408376963  14.943960149  0.8261105110  0.1394424438  750           0.0249771013 
Best model upto now
0.9546071429  0.9539285714  0.7701250000  0.7540000000  0.3327304372  0.3240051874  0.7882938979  0.7880299252  0.4893366479  0.4916230366  19.925280199  0.5841203442  0.1394424438  1000          0.0237696352 
Best model upto now
0.9576607143  0.9567142857  0.8205000000  0.8075000000  0.3280210217  0.3218892908  0.7914072229  0.7930174564  0.5237472197  0.5277486911  24.906600249  0.4876274448  0.1394424438  1250          0.0250803566 
Best model upto now
0.9653214286  0.9645000000  0.8177500000  0.8040000000  0.3714466096  0.3627738721  0.7970112080  0.7780548628  0.5313358629  0.5345549738  29.887920298  0.4100247512  0.1394424438  1500          0.0256719742 
Best model upto now
0.9678392857  0.9648571429  0.8073750000  0.7960000000  0.3730846671  0.3670056651  0.8013698630  0.7955112219  0.5283265733  0.5350785340  34.869240348  0.3529106822  0.1394424438  1750          0.0242733250 
Best model upto now
0.9671785714  0.9655000000  0.8366250000  0.8190000000  0.3425417193  0.3358815098  0.7808219178  0.7730673317  0.5198220594  0.5308900524  39.850560398  0.3814480383  0.1394424438  2000          0.0244274750 
Best model upto now
0.9742678571  0.9723571429  0.8403750000  0.8260000000  0.3933897553  0.3874820831  0.8100871731  0.8079800499  0.5606437263  0.5617801047  44.831880448  0.2852212038  0.1394424438  2250          0.0237074633 
0.9717500000  0.9695000000  0.7828750000  0.7480000000  0.4008633928  0.3893932155  0.8188044832  0.8129675810  0.5624754677  0.5727748691  49.813200498  0.2809189868  0.1394424438  2500          0.0253075190 
Best model upto now
0.9745000000  0.9725714286  0.8548750000  0.8375000000  0.3449476163  0.3397720292  0.8069738481  0.8104738155  0.5728117231  0.5879581152  54.794520547  0.2703543081  0.1394424438  2750          0.0235216379 
Best model upto now
0.9780357143  0.9764285714  0.8441250000  0.8210000000  0.4074156230  0.4007235001  0.8300124533  0.8279301746  0.5934842339  0.6094240838  59.775840597  0.2864494568  0.1394424438  3000          0.0237979212 
Best model upto now
0.9801428571  0.9786428571  0.8565000000  0.8465000000  0.3901136402  0.3824994881  0.8194271482  0.8179551122  0.5882506869  0.5905759162  64.757160647  0.2561838533  0.1394424438  3250          0.0251150265 
Best model upto now
0.9821250000  0.9805714286  0.8570000000  0.8465000000  0.4069378562  0.3977885469  0.8275217933  0.8304239401  0.5903441057  0.5910994764  69.738480697  0.2146121736  0.1394424438  3500          0.0239350424 
0.9800357143  0.9770000000  0.8565000000  0.8410000000  0.4352967273  0.4247491639  0.8356164384  0.8054862843  0.5954468141  0.5994764398  74.719800747  0.2141920160  0.1394424438  3750          0.0245730829 
0.9808571429  0.9785714286  0.8623750000  0.8450000000  0.4210319762  0.4111664733  0.8268991283  0.8329177057  0.6027737799  0.6099476440  79.701120797  0.2195588097  0.1394424438  4000          0.0261926298 
0.9789464286  0.9762142857  0.8460000000  0.8355000000  0.3983039279  0.3894614702  0.7963885430  0.7955112219  0.5828863012  0.5874345550  84.682440846  0.2264932705  0.1394424438  4250          0.0249796591 
Best model upto now
0.9843750000  0.9823571429  0.8605000000  0.8580000000  0.4120397229  0.4037267081  0.8163138232  0.8054862843  0.6066989402  0.6183246073  89.663760896  0.2083320250  0.1394424438  4500          0.0254494934 
0.9846428571  0.9814285714  0.8657500000  0.8490000000  0.4609425656  0.4544399700  0.8275217933  0.8229426434  0.6124558419  0.6261780105  94.645080946  0.1947180774  0.1394424438  4750          0.0254492970 
Best model upto now
0.9845535714  0.9831428571  0.8552500000  0.8440000000  0.4682285090  0.4586035083  0.8430884184  0.8229426434  0.6171660343  0.6267015707  99.626400996  0.1966990961  0.1394424438  5000          0.0258623657 
Best model upto now
0.9857678571  0.9838571429  0.8668750000  0.8615000000  0.4652083404  0.4577844516  0.8237858032  0.8154613466  0.6197828078  0.6324607330  104.60772104  0.2033684206  0.1394424438  5250          0.0251819458 
0.9848035714  0.9822857143  0.8591250000  0.8430000000  0.4587414258  0.4535526585  0.8462017435  0.8428927681  0.6209603559  0.6251308901  109.58904109  0.1756522343  0.1394424438  5500          0.0260543985 
Best model upto now
0.9865000000  0.9847142857  0.8653750000  0.8530000000  0.4431628161  0.4368985052  0.8362391034  0.8329177057  0.6204370012  0.6209424084  114.57036114  0.1761036043  0.1394424438  5750          0.0258577538 
Best model upto now
0.9871964286  0.9856428571  0.8662500000  0.8550000000  0.4474627171  0.4431096853  0.8343711083  0.8379052369  0.6222687426  0.6298429319  119.55168119  0.1786347516  0.1394424438  6000          0.0246920452 
0.9876607143  0.9855714286  0.8732500000  0.8520000000  0.4454322083  0.4390826565  0.8362391034  0.8279301746  0.6332591914  0.6439790576  124.53300124  0.1702091809  0.1394424438  6250          0.0258072138 
Best model upto now
0.9876785714  0.9858571429  0.8775000000  0.8710000000  0.4484523769  0.4436557232  0.8331257783  0.8154613466  0.6269789350  0.6335078534  129.51432129  0.1491051231  0.1394424438  6500          0.0252138214 
Best model upto now
0.9883035714  0.9862142857  0.8765000000  0.8635000000  0.4469166979  0.4362159580  0.8343711083  0.8129675810  0.6243621615  0.6293193717  134.49564134  0.1673380408  0.1394424438  6750          0.0257008276 
Best model upto now
0.9892678571  0.9869285714  0.8772500000  0.8630000000  0.4555506262  0.4503446864  0.8343711083  0.8104738155  0.6327358367  0.6471204188  139.47696139  0.1410846024  0.1394424438  7000          0.0255302448 
0.9863928571  0.9817857143  0.8682500000  0.8560000000  0.4573251885  0.4508907242  0.8412204234  0.8254364090  0.6295957085  0.6308900524  144.45828144  0.1458790559  0.1394424438  7250          0.0237041836 
0.9874821429  0.9863571429  0.8586250000  0.8495000000  0.4453980821  0.4376493072  0.8356164384  0.8079800499  0.6204370012  0.6188481675  149.43960149  0.1494505506  0.1394424438  7500          0.0258906488 
Best model upto now
0.9898035714  0.9877857143  0.8713750000  0.8570000000  0.4631266423  0.4547812436  0.8399750934  0.8229426434  0.6350909329  0.6455497382  154.42092154  0.1635303549  0.1394424438  7750          0.0258396149 
0.9900178571  0.9865714286  0.8755000000  0.8630000000  0.4302631130  0.4232475599  0.8312577833  0.8129675810  0.6310349339  0.6376963351  159.40224159  0.1228114042  0.1394424438  8000          0.0257281122 
0.9873571429  0.9856428571  0.8493750000  0.8360000000  0.4659591168  0.4583987441  0.8536737235  0.8403990025  0.6375768677  0.6397905759  164.38356164  0.1262244434  0.1394424438  8250          0.0251300001 
Best model upto now
0.9910178571  0.9878571429  0.8668750000  0.8525000000  0.4823055660  0.4761449730  0.8418430884  0.8254364090  0.6265864189  0.6335078534  169.36488169  0.1321966024  0.1394424438  8500          0.0254983912 
0.9888928571  0.9857142857  0.8698750000  0.8515000000  0.4525475207  0.4454303461  0.8381070984  0.8229426434  0.6361376423  0.6481675393  174.34620174  0.1737698120  0.1394424438  8750          0.0238202839 
Best model upto now
0.9906250000  0.9882142857  0.8768750000  0.8725000000  0.4289663174  0.4222919937  0.8331257783  0.8029925187  0.6243621615  0.6340314136  179.32752179  0.1383340361  0.1394424438  9000          0.0254085789 
Best model upto now
0.9906250000  0.9882142857  0.8707500000  0.8565000000  0.4900351500  0.4854276159  0.8542963885  0.8279301746  0.6383618998  0.6450261780  184.30884184  0.1170775140  0.1394424438  9250          0.0245088444 
Best model upto now
0.9908571429  0.9884285714  0.8632500000  0.8490000000  0.4791659557  0.4720496894  0.8493150685  0.8154613466  0.6449038336  0.6539267016  189.29016189  0.1414690346  0.1394424438  9500          0.0236364574 
Best model upto now
0.9913750000  0.9904285714  0.8702500000  0.8615000000  0.4799508583  0.4749846427  0.8542963885  0.8204488778  0.6350909329  0.6408376963  194.27148194  0.1264058269  0.1394424438  9750          0.0254636488 
0.9910892857  0.9889285714  0.8667500000  0.8520000000  0.4971845886  0.4911610129  0.8561643836  0.8204488778  0.6360068036  0.6397905759  199.23287671  0.1252952408  0.1394424438  9999          0.0255032878 

Not launched: ./Results/DIGITS/RandConv/t1234_s0 ('DIGITS', 'RandConv', [1, 2, 3, 4], 0)
1 jobs: 0 done, 0 incomplete, 1 not launched.
python -m domainbed.scripts.train --algorithm RandConv --data_dir /home/kavindya/data/Models/DATA --dataset DIGITS --holdout_fraction 0.2 --hparams '{"batch_size":32,"lr":5e-05,"resnet_dropout":0.0,"weight_decay":0.0}' --hparams_seed 0 --output_dir ./Results/DIGITS/RandConv/t1234_s0 --seed 1270687741 --task domain_generalization --test_envs 1 2 3 4 --trial_seed 0
About to launch 1 jobs.
Good to go
Launching...
Making job directories:
WARNING: using experimental multi_gpu_launcher.
Launched 1 jobs!
